{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn                         import datasets\n",
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "from pybrain.supervised.trainers     import BackpropTrainer\n",
    "from pybrain.tools.shortcuts         import buildNetwork\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "dataset = ClassificationDataSet(4,1,nb_classes=3)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    dataset.addSample(x[i], y[i])\n",
    "\n",
    "train_data, part_data = dataset.splitWithProportion(0.6)\n",
    "print(\"quantidade de treino: %d\" % len(train_data))\n",
    "\n",
    "test_data, val_data = part_data.splitWithProportion(0.5)\n",
    "print(\"quantidade de teste: %d\" % len(test_data))\n",
    "print(\"quantidade de validação: %d\" % len(val_data))\n",
    "\n",
    "net = buildNetwork(dataset.indim, 3, dataset.outdim)\n",
    "trainer = BackpropTrainer(net, dataset=train_data, learningrate=0.01,momentum=0.1, verbose=True)\n",
    "train_errors, val_errors = trainer.trainUntilConvergence(dataset=train_data, maxEpochs=100)\n",
    "\n",
    "plt.plot(train_errors, 'b', val_errors, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before _convertToOneOfMany...\n",
      "[[1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]]\n",
      "After _convertToOneOfMany...\n",
      "[[0 1 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "--------------------------------------\n",
      "Erro de teste: 6.666667\n",
      "--------------------------------------\n",
      "Erro de validação: 3.333333\n",
      "--------------------------------------\n",
      "Validação\n",
      "saida da rede:\t [2 1 2 2 2 2 0 1 0 1 1 2 1 2 2 1 0 0 1 2 2 2 1 0 0 1 2 2 0 2]\n",
      "correto:\t [2 1 2 2 2 2 0 1 0 1 1 2 1 2 2 1 0 0 1 2 2 2 1 0 0 1 2 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn                         import datasets\n",
    "from pybrain.datasets.classification import ClassificationDataSet\n",
    "from pybrain.supervised.trainers     import BackpropTrainer\n",
    "from pybrain.tools.shortcuts         import buildNetwork\n",
    "from pybrain.structure.modules       import SoftmaxLayer\n",
    "from pybrain.utilities               import percentError\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "dataset = ClassificationDataSet(4,1, nb_classes=3)\n",
    "\n",
    "for i in range(len(x)):\n",
    "    dataset.addSample(x[i], y[i])\n",
    "\n",
    "train_data_temp, part_data_temp = dataset.splitWithProportion(0.6)\n",
    "test_data_temp, val_data_temp = part_data_temp.splitWithProportion(0.5)\n",
    "\n",
    "train_data = ClassificationDataSet(4,1,nb_classes=3)\n",
    "for n in range(train_data_temp.getLength()):\n",
    "    train_data.addSample(train_data_temp.getSample(n)[0], train_data_temp.getSample(n)[1])\n",
    "    \n",
    "test_data = ClassificationDataSet(4,1,nb_classes=3)\n",
    "for n in range(test_data_temp.getLength()):\n",
    "    test_data.addSample(test_data_temp.getSample(n)[0], test_data_temp.getSample(n)[1])\n",
    "\n",
    "val_data = ClassificationDataSet(4,1,nb_classes=3)\n",
    "for n in range(val_data_temp.getLength()):\n",
    "    val_data.addSample(val_data_temp.getSample(n)[0], val_data_temp.getSample(n)[1])\n",
    "\n",
    "print('Before _convertToOneOfMany...')\n",
    "print(train_data['target'][:5])\n",
    "\n",
    "train_data._convertToOneOfMany()\n",
    "test_data._convertToOneOfMany()\n",
    "val_data._convertToOneOfMany()\n",
    "\n",
    "print('After _convertToOneOfMany...')\n",
    "print(train_data['target'][:5])\n",
    "\n",
    "print('--------------------------------------')\n",
    "\n",
    "net = buildNetwork(4,5,3, outclass=SoftmaxLayer)\n",
    "trainer = BackpropTrainer(net, dataset=train_data, learningrate=0.01, momentum=0.1)\n",
    "trainer.trainOnDataset(train_data, 100)\n",
    "\n",
    "out = net.activateOnDataset(test_data).argmax(axis=1)\n",
    "print(\"Erro de teste: %f\" % percentError(out, test_data['class']))\n",
    "\n",
    "print('--------------------------------------')\n",
    "\n",
    "out = net.activateOnDataset(val_data).argmax(axis=1)\n",
    "print(\"Erro de validação: %f\" % percentError(out, val_data['class']))\n",
    "\n",
    "print('--------------------------------------')\n",
    "\n",
    "print(\"Validação\")\n",
    "print('saida da rede:\\t', out)\n",
    "print('correto:\\t', val_data['class'][:,0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
